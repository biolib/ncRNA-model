{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biolib\n",
    "import os\n",
    "from dataset.dataset_preprocessing import split_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 11:41:10,965 | INFO : Loaded project ncRNA-foundational-model/baseline-train-and-evaluate:0.0.48\n"
     ]
    }
   ],
   "source": [
    "app = biolib.load('ncRNA-foundational-model/baseline-train-and-evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_MODEL_DEEP = \"configs/model/1dcnn/1d_cnn_deep.yml\"\n",
    "CFG_MODEL_SHALLOW = \"configs/model/1dcnn/1d_cnn_shallow.yml\"\n",
    "TRANSFORMER_MODEL_CFG = \"configs/model/transformer.yml\"\n",
    "\n",
    "GENERAL_CONFIG = 'configs/general.yml'\n",
    "TRANSFORMER_GENERAL_CONFIG = 'configs/general_transformer.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 11:41:20,592 | INFO : View the result in your browser at: https://biolib.com/results/f4329e3e-ae0a-4ee1-b20f-d16f820c0757/\n",
      "2025-05-21 11:41:26,415 | INFO : View the result in your browser at: https://biolib.com/results/2d798d01-f698-495d-8d2e-c2c6d968b5a1/\n",
      "2025-05-21 11:41:31,829 | INFO : View the result in your browser at: https://biolib.com/results/cffba0ec-5d3f-4b50-94fc-99543333d067/\n",
      "2025-05-21 11:41:36,705 | INFO : View the result in your browser at: https://biolib.com/results/e978f894-3539-4575-9b0e-d3fdd84924bc/\n",
      "2025-05-21 11:41:41,759 | INFO : View the result in your browser at: https://biolib.com/results/edde309b-5c34-4937-9208-82cd23bee2a5/\n",
      "2025-05-21 11:41:47,181 | INFO : View the result in your browser at: https://biolib.com/results/95ed63f8-501b-46b1-a683-73c16130c60c/\n",
      "2025-05-21 11:41:53,578 | INFO : View the result in your browser at: https://biolib.com/results/245e0d44-5583-4c5a-9b77-c8676d8d5eec/\n",
      "2025-05-21 11:42:00,321 | INFO : View the result in your browser at: https://biolib.com/results/f54952cb-72b6-493a-8277-5e01154a4cc2/\n",
      "2025-05-21 11:42:06,951 | INFO : View the result in your browser at: https://biolib.com/results/6bf7bde2-7358-4c04-ab47-e8cb34aa7d1b/\n",
      "2025-05-21 11:42:14,466 | INFO : View the result in your browser at: https://biolib.com/results/c43895e1-5a15-460e-be41-0ea1544198d4/\n",
      "2025-05-21 11:42:20,299 | INFO : View the result in your browser at: https://biolib.com/results/48139ad1-91ab-4d2a-adfb-aac05559259e/\n",
      "2025-05-21 11:42:26,621 | INFO : View the result in your browser at: https://biolib.com/results/5c10cd4d-ae71-4b97-b58d-98662560705e/\n",
      "2025-05-21 11:42:35,761 | INFO : View the result in your browser at: https://biolib.com/results/96cf0f40-b097-48f9-8aba-57a2536e92ce/\n",
      "2025-05-21 11:42:44,762 | INFO : View the result in your browser at: https://biolib.com/results/19a5cdeb-c746-4624-8e29-084c865c45b3/\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "experiment = biolib.Experiment('RNA1-CNN-DEEP-SHALLOW-1')\n",
    "dataset_fastas = [\"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.9_7-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_7-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.8_7-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_3-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_5-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_1-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\"]\n",
    "config_paths = [CFG_MODEL_DEEP, CFG_MODEL_SHALLOW]\n",
    "\n",
    "with experiment:\n",
    "    for i, dataset_fasta in enumerate(dataset_fastas):\n",
    "        for cfg in config_paths:\n",
    "            if i == 1: # Trying different dataset sizes with .85 7-sp\n",
    "                args = [\n",
    "                        \"-a\", \"cnn\",\n",
    "                        \"-c\", cfg,\n",
    "                        \"-i\", dataset_fasta,\n",
    "                        \"--log_wandb\",\n",
    "                        \"--wandb_config\", GENERAL_CONFIG,\n",
    "                        \"--finetune_batch_size\", \"1024\",\n",
    "                        \"--finetune_num_epochs\", \"50\",\n",
    "                        \"--start_subset_size\", \"1000\"\n",
    "                    ]\n",
    "                job = app.cli(args, blocking=False)\n",
    "            args = [\n",
    "                \"-a\", \"cnn\",\n",
    "                \"-c\", cfg,\n",
    "                \"-i\", dataset_fasta,\n",
    "                \"--log_wandb\",\n",
    "                \"--wandb_config\", GENERAL_CONFIG,\n",
    "                \"--finetune_batch_size\", \"1024\",\n",
    "                \"--finetune_num_epochs\", \"50\",\n",
    "                \"--start_subset_size\", \"100000000\"\n",
    "            ]\n",
    "            job = app.cli(args, blocking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 10:58:16,572 | INFO : View the result in your browser at: https://biolib.com/results/2676c24a-c596-43f0-b0cd-cd87652597b6/\n",
      "2025-05-21 10:58:22,208 | INFO : View the result in your browser at: https://biolib.com/results/1fffa25a-59db-4b1d-820f-aab255b83686/\n",
      "2025-05-21 10:58:28,039 | INFO : View the result in your browser at: https://biolib.com/results/5f8d2666-8314-43d2-90ad-1a1556943047/\n",
      "2025-05-21 10:58:31,355 | INFO : View the result in your browser at: https://biolib.com/results/973188e9-0b78-41dd-98f7-bf6b54314d7b/\n",
      "2025-05-21 10:58:32,415 | INFO : View the result in your browser at: https://biolib.com/results/fd5e9813-0ec2-4f95-a701-a4ce417debb8/\n",
      "2025-05-21 10:58:39,083 | INFO : View the result in your browser at: https://biolib.com/results/43d93ba5-21da-4430-a4b9-deae01bc782d/\n",
      "2025-05-21 10:58:40,556 | INFO : View the result in your browser at: https://biolib.com/results/e810c1c2-5b99-4d29-a0ac-349ab7727e10/\n",
      "2025-05-21 10:58:44,981 | INFO : View the result in your browser at: https://biolib.com/results/462815cf-997f-493f-b3b9-560a669ebeef/\n",
      "2025-05-21 10:58:49,312 | INFO : View the result in your browser at: https://biolib.com/results/9780e759-aaa2-46d6-8777-66bff645cc66/\n",
      "2025-05-21 10:58:53,029 | INFO : View the result in your browser at: https://biolib.com/results/f5a1835d-f92c-4162-a65b-497362d3fbe4/\n",
      "2025-05-21 10:58:54,167 | INFO : View the result in your browser at: https://biolib.com/results/ec3750da-3b52-41b7-b4fa-83f9df07f7ba/\n",
      "2025-05-21 10:59:04,519 | INFO : View the result in your browser at: https://biolib.com/results/f1b17140-dc81-4516-b6f1-2a633793c017/\n"
     ]
    }
   ],
   "source": [
    "dataset_fastas = [\"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.9_7-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_7-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.8_7-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_3-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_5-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\",\n",
    "                  \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.85_1-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\"]\n",
    "\n",
    "experiment = biolib.Experiment('RNA1-TRANSFORMER')\n",
    "\n",
    "with experiment:\n",
    "    for i, dataset_fasta in enumerate(dataset_fastas):\n",
    "        if i == 1: # Trying different dataset sizes with .85 7-sp\n",
    "            args = [\n",
    "            \"-a\", \"transformer\",\n",
    "            \"-t\", TRANSFORMER_MODEL_CFG,\n",
    "            \"-i\", dataset_fasta,\n",
    "            \"--log_wandb\",\n",
    "            \"--wandb_config\", TRANSFORMER_GENERAL_CONFIG,\n",
    "            \"--start_subset_size\", \"1000\",\n",
    "            \"--finetune_batch_size\", \"1024\",\n",
    "            \"--finetune_num_epochs\", \"50\"\n",
    "        ]\n",
    "        job = app.cli(args, blocking=False)\n",
    "        args = [\n",
    "            \"-a\", \"transformer\",\n",
    "            \"-t\", TRANSFORMER_MODEL_CFG,\n",
    "            \"-i\", dataset_fasta,\n",
    "            \"--log_wandb\",\n",
    "            \"--wandb_config\", TRANSFORMER_GENERAL_CONFIG,\n",
    "            \"--start_subset_size\", \"100000000\",\n",
    "            \"--finetune_batch_size\", \"1024\",\n",
    "            \"--finetune_num_epochs\", \"50\"\n",
    "        ]\n",
    "        job = app.cli(args, blocking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    \"embedding_dim\": [64, 128, 256],\n",
    "    \"hidden_dim\": [128, 256, 512],\n",
    "    \"num_layers\": [2, 3, 4, 6],\n",
    "    \"kernel_size\": [5, 7, 11, 15],\n",
    "    \"dropout_rate\": [0.1, 0.2],\n",
    "    \"batch_size\": [1024],\n",
    "    \"learning_rate\": [0.001, 0.0005, 0.0001]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_CONFIG = 'configs/general.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "os.makedirs(\"/tmp/model_configs\", exist_ok=True)\n",
    "\n",
    "# SMALL\n",
    "grid_params = {\n",
    "    \"embedding_dim\": [64, 128],\n",
    "    \"hidden_dim\": [128, 256, 512],\n",
    "    \"num_layers\": [2, 4, 6],\n",
    "    \"kernel_size\": [7, 11, 15],\n",
    "    \"dropout_rate\": [0.1],\n",
    "    \"batch_size\": [1024],\n",
    "    \"learning_rate\": [0.0005]\n",
    "}\n",
    "\n",
    "# Generate valid combinations\n",
    "valid_configs = []\n",
    "config_paths = []\n",
    "\n",
    "# Get all combinations of parameters\n",
    "keys = list(grid_params.keys())\n",
    "combinations = list(itertools.product(*(grid_params[key] for key in keys)))\n",
    "\n",
    "for combo in combinations:\n",
    "    # Create a dictionary with parameter names and values\n",
    "    params = dict(zip(keys, combo))\n",
    "    \n",
    "    # Create the config dictionary with the structure from 1d_cnn.yml\n",
    "    config = {\n",
    "        \"model\": {\n",
    "            \"embedding_dim\": params[\"embedding_dim\"],\n",
    "            \"hidden_dim\": params[\"hidden_dim\"],\n",
    "            \"num_layers\": params[\"num_layers\"],\n",
    "            \"kernel_size\": params[\"kernel_size\"],\n",
    "            \"dropout_rate\": params[\"dropout_rate\"]\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"batch_size\": params[\"batch_size\"],\n",
    "            \"num_epochs\": 100,  # Fixed value from original config\n",
    "            \"learning_rate\": params[\"learning_rate\"],\n",
    "            \"model_save_path\": \"/home/biolib/output\"  # Fixed value from original config\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    valid_configs.append(config)\n",
    "    \n",
    "    # Generate a unique filename\n",
    "    filename = f\"/tmp/model_configs/config_ed{params['embedding_dim']}_hd{params['hidden_dim']}_nl{params['num_layers']}_ks{params['kernel_size']}_dr{params['dropout_rate']}_bs{params['batch_size']}_lr{params['learning_rate']}.yml\"\n",
    "    \n",
    "    # Save the config to a YAML file\n",
    "    with open(filename, 'w') as file:\n",
    "        yaml.dump(config, file, default_flow_style=False)\n",
    "    \n",
    "    config_paths.append(filename)\n",
    "\n",
    "print(f\"Generated {len(valid_configs)} configuration files\")\n",
    "print(f\"File paths are stored in config_paths array with {len(config_paths)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import sleep\n",
    "\n",
    "experiment = biolib.Experiment('RNA1-CNN-GRIDSEARCH-3')\n",
    "dataset_fasta = \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-flanked-new/conservation_0/run_0.9_7-sp_querycons0.0_conserved_alignment_mmseqs_clustered.fasta\"\n",
    "\n",
    "with experiment:\n",
    "\n",
    "    for cfg in config_paths:\n",
    "        args = [\n",
    "            \"-a\", \"cnn\",\n",
    "            \"-c\", cfg,\n",
    "            \"-i\", dataset_fasta,\n",
    "            \"--log_wandb\",\n",
    "            \"--wandb_config\", GENERAL_CONFIG,\n",
    "            \"-p\",\n",
    "            \"--start_subset_size\", \"10000000\"\n",
    "        ]\n",
    "        job = app.cli(args, blocking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_MODES = [\"alignment_only\", \"full_sequence\"]\n",
    "CONSERVATION_MODES = [\"conservation_0\", \"conservation_0.5\"]\n",
    "SEQ_ID = [0.75, 0.8, 0.85,0.9, 0.95, 0.99]\n",
    "N_HITS = [1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATASET_DIR = \"/home/ec2-user/apps/app-baseline-train-and-evaluate/clustered-dataset-new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(base_dir, dataset_mode, conservation_mode, seq_id, n_hits):\n",
    "    wildcard = \"alignment\" if dataset_mode == \"alignment_only\" else \"sequences\"\n",
    "    if dataset_mode == \"\":\n",
    "        return os.path.join(base_dir, f\"{conservation_mode}/run_{seq_id}_{n_hits}-sp_querycons{float(conservation_mode.split('_')[1]):.1f}_conserved_{wildcard}_mmseqs_clustered.fasta\")\n",
    "    else:\n",
    "        return os.path.join(base_dir, f\"{dataset_mode}/{conservation_mode}/run_{seq_id}_{n_hits}-sp_querycons{float(conservation_mode.split('_')[1]):.1f}_conserved_{wildcard}_mmseqs_clustered.fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    \"--model_architecture\", \"cnn\",\n",
    "    \"--input_fasta\", \"10000_rnacentral.fasta\",\n",
    "    \"--log_wandb\",\n",
    "    \"--wandb_config\", GENERAL_CONFIG\n",
    "]\n",
    "#job = app.cli(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = []\n",
    "# for dataset_mode in DATASET_MODES:\n",
    "#     dataset_mode_counts = []\n",
    "#     for conservation_mode in CONSERVATION_MODES:\n",
    "#         cons_mode_counts = []\n",
    "#         for seq_id in SEQ_ID:\n",
    "#             seq_id_counts = []\n",
    "#             for n_hits in N_HITS:\n",
    "#                 fasta_path = get_path(BASE_DATASET_DIR, dataset_mode, conservation_mode, seq_id, n_hits)\n",
    "#                 if os.path.exists(fasta_path):\n",
    "#                     print(f\"Processing: {fasta_path}\")\n",
    "#                     _, _, train_size, val_size = split_sequences(fasta_path, 512, \"/tmp\", 10000, 0.95, None, None, count_only=True)\n",
    "#                     seq_id_counts.append(train_size + val_size)\n",
    "#                 else:\n",
    "#                     seq_id_counts.append(0)\n",
    "                \n",
    "#             cons_mode_counts.append(seq_id_counts)\n",
    "#         dataset_mode_counts.append(cons_mode_counts)\n",
    "#     counts.append(dataset_mode_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print counts in a more readable format\n",
    "# print(\"\\nDataset counts by mode, conservation, sequence ID, and number of hits:\")\n",
    "# print(\"-\" * 80)\n",
    "# for dataset_idx, dataset_mode in enumerate(DATASET_MODES):\n",
    "#     print(f\"\\n{dataset_mode.replace('_', ' ').title()}:\")\n",
    "#     for cons_idx, conservation_mode in enumerate(CONSERVATION_MODES):\n",
    "#         conservation_value = float(conservation_mode.split('_')[1])\n",
    "#         print(f\"\\n  Conservation {conservation_value:.1f}:\")\n",
    "#         for seq_idx, seq_id in enumerate(SEQ_ID):\n",
    "#             print(f\"\\n    Sequence ID {seq_id}:\")\n",
    "#             print(\"      Hits:\", end=\" \")\n",
    "#             for hit_idx, n_hits in enumerate(N_HITS):\n",
    "#                 count = counts[dataset_idx][cons_idx][seq_idx][hit_idx]\n",
    "#                 print(f\"{n_hits}: {count:,}\", end=\"  \")\n",
    "#             print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import matplotlib.ticker as mticker\n",
    "\n",
    "# # Create a figure with 4 subplots (one for each dataset_mode Ã— conservation_mode combination)\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(20, 16))\n",
    "# fig.tight_layout(pad=4.0)\n",
    "\n",
    "# # Flatten the axs array for easier indexing\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# # For each dataset_mode and conservation_mode combination\n",
    "# plot_idx = 0\n",
    "# for dataset_idx, dataset_mode in enumerate(DATASET_MODES):\n",
    "#     for cons_idx, conservation_mode in enumerate(CONSERVATION_MODES):\n",
    "#         # Access the correct data in counts using the proper structure\n",
    "#         # counts[dataset_idx][cons_idx][seq_idx]\n",
    "        \n",
    "#         # Get the subplot for this combination\n",
    "#         ax = axs[plot_idx]\n",
    "        \n",
    "#         # Extract conservation value and format it with one decimal place\n",
    "#         conservation_value = float(conservation_mode.split('_')[1])\n",
    "#         title = f\"{dataset_mode.replace('_', ' ').title()} - Conservation {conservation_value:.1f}\"\n",
    "        \n",
    "#         # Set up bar positions\n",
    "#         bar_width = 0.1\n",
    "#         bar_positions = np.arange(len(N_HITS))\n",
    "        \n",
    "#         # For each sequence ID\n",
    "#         for seq_idx, seq_id_val in enumerate(SEQ_ID):\n",
    "#             # Plot data for this sequence ID - using correct indexing\n",
    "#             counts_data = counts[dataset_idx][cons_idx][seq_idx]\n",
    "            \n",
    "#             # Calculate position for this group of bars\n",
    "#             offset = (seq_idx - len(SEQ_ID)/2 + 0.5) * bar_width\n",
    "            \n",
    "#             # Plot bars\n",
    "#             bars = ax.bar(bar_positions + offset, counts_data, \n",
    "#                      width=bar_width, \n",
    "#                      label=f\"Seq ID {seq_id_val}\")\n",
    "        \n",
    "#         # Configure subplot\n",
    "#         ax.set_title(title, fontsize=14)\n",
    "#         ax.set_xlabel(\"Number of Hits\", fontsize=12)\n",
    "#         ax.set_ylabel(\"Count (Train + Val Size)\", fontsize=12)\n",
    "#         ax.set_xticks(bar_positions)\n",
    "#         ax.set_xticklabels(N_HITS)\n",
    "#         ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "        \n",
    "#         # Set logarithmic scale for y-axis\n",
    "#         ax.set_yscale('log')\n",
    "        \n",
    "#         # Format y-axis tick labels with scientific notation\n",
    "#         ax.yaxis.set_major_formatter(mticker.ScalarFormatter(useMathText=True))\n",
    "#         ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "#         # Format y-axis tick labels\n",
    "#         #ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.1f}'))\n",
    "        \n",
    "#         # Only add legend to the first plot\n",
    "#         if plot_idx == 0:\n",
    "#             ax.legend(title=\"Sequence ID\", bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=len(SEQ_ID))\n",
    "        \n",
    "#         plot_idx += 1\n",
    "\n",
    "# plt.suptitle(\"Sequence Counts by Dataset Mode, Conservation Mode, and Sequence ID (Log Scale)\", fontsize=18)\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "# plt.savefig('counts_by_mode_log_barchart.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"exp1\": [\n",
    "        ()\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
