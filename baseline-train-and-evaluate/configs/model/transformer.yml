model:
  embedding_dim: 128
  num_heads: 4
  num_layers: 6
  dim_feedforward: 256
  dropout_rate: 0.3

training:
  batch_size: 1024 
  num_epochs: 300
  learning_rate: 0.001
  model_save_path: "output/transformer_models"
